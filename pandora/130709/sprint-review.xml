<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="../deck1/slides.xsl"?>
<slides>
    <dependencies>
        <script src="http://openlayers.org/api/OpenLayers.js"></script>
        <link rel="stylesheet" href="extra/mnr-demo.css"/>
    </dependencies>

    <title>Sprint Review Pandora</title>

    <sprint>
        <started>9th of July 2013</started>
        <ended>5th of August 2013</ended>
        <productowner>Timothy Grymonpon</productowner>
        <scrummaster>Timothy Grymonpon</scrummaster>
        <teammembers>Charlotte, Christophe, Dominique, Jan, Jelle, Kevin, Pieter, Plamen, Rebekka</teammembers>
        <goal>
            <ul>
                <li>Make a successfull MNR prototype 7 with larger coverage</li>
                <li>Present MN-R demo to the maps leadership team</li>
            </ul>
        </goal>
    </sprint>

    <story epic="[MNR INFRA]" title="Automated setup of virtual machines to run TIF2TTOM and MNR conversions" status="not-done" sp="3">
        <slide>
            <img src="img/deployment_frequency.png"/>
        </slide>
        <slide>
            <img src="img/infrastructure_as_software.png" width="60%"/>
            <div align="center" style="color: red">DevOps: infrastructure as software</div>
        </slide>
        <slide>
            <p>In December 2011, we successfully deployed in one sprint time the entire TIF2MN process on an Amazon cloud.  Since then,
            we've been promised access to an internal cloud infrastructure, but that's still not available today... <b style="color: red">Not having access
            to such infrastructure prevents us to book progress on continuous deployment.</b></p>
            <p>We are using VirtualBox on our laptops since multiple years as <em>poor man's solution</em> to build &amp; destroy virtual 
            machines. As enabler for continuous deployment, we want to combine this VirtualBox solution with our nightly builds.</p>
            <p>Already realized (see build plans and running VM's on <a href="http://besrvud-mnr01:8080/">our MNR development server</a>):</p>
            <ul>
                <li>Automated CentOS linux installation (=free alternative for RedHat)</li>
                <li>Puppetized Oracle database server installation</li>
                <li>Puppetized deployment of all software required for running TIF2TTOM and MNR conversions</li>
            </ul>
            <p>Still missing:</p>
            <ul>
                <li>Full TIF2TTOM test run to verify machines are correctly configured</li>
                <li>Run TIF2TTOM and MNR nightly build processes on our own freshly deployed virtual machines</li>
            </ul>
        </slide>
        <slide>
            <img src="img/tweet1.png"/>
            <img src="img/tweet2.png"/>
            <p/>
            <div align="center">Original link to TomTom case study: click <a href="https://cwiki.apache.org/confluence/download/attachments/30757703/TomTom+Case+Study+Final+071613.pdf">here</a></div>
        </slide>
    </story>

    <story epic="[MNR MAINT]" title="Upgrade Hakuna Matata data to NCS22" status="done" sp="2">
        <slide>
            <p>As enabler for continuous integration of NCS22 developments, we need test data in 22 format:</p>
            <ul>
                <li>H&amp;M test data in TIF 22 format is urgently required for TIF2TTOM developments (CPP 3.8RMC)</li>
                <li>H&amp;M test data in TIF 21 format is still required for MultiNet mapline</li>
            </ul>
            <p>As of now, testers can use TA-Mapper to edit TIF22 content in H&amp;M; new <a href="http://ci.tomtomgroup.com:8080/jenkins/view/Productcreate/view/save-as/view/save-as-rita/view/tif2asc/">Jenkins build plans</a> will automatically run TIF2ASC.</p>
        </slide>
    </story>

    <story epic="[MNR MAINT]" title="Package, document and release MNR prototype 7" status="done" sp="1">
        <slide>
            <p>MNR prototype 7 has been made available for customers:</p>
            <ul>
                <li>official MNR D64 prototype containing Volkswagen traffic signs and overtaking restrictions</li>
                <li>new geographical coverage (focus shifted from EUR to NAM): seamed states of California, Arizona, Nevada</li>
                <li>delta records for two different versions of dataset UC3 (no Andorra any more...)</li>
            </ul>
            <p>New customer added for MNR prototypes: <a href="http://www.benomad.com/">BeNomad</a></p>
        </slide>
    </story>

    <story epic="[MNR MAINT]" title="Upgrade MN-R demo for maps leadership team" status="done" sp="3">
        <slide>
            <ul>
                <li>MN-R demo illustrating realisations of Q1/Q2 2013 has been improved (you can find it on <a href="http://cats/sprint-reviews/pandora/mnr-demo-2/#/">cats</a>)</li>
                <li>The improved version of the demo has been given to (and was appreciated by) the entire maps leadership team</li>
                <li>Expect a new demo at the end of the year zooming in on Q3/Q4 achievements!</li>
            </ul>
        </slide>
    </story>

    <story epic="[MNR MAINT]" title="Prepare training on how to build products with CDP infrastructure" status="done" sp="2">
        <slide>
            <p>In august, software engineers from MultiNet and Automotive maplines (Lodz) come to Ghent for practical training: how to build products using the available CDP infrastructure?</p>
            <p>Goal is to have practical hands-on-the-keyboard sessions: they will learn CDP by implementing MNR layers</p>
            <ul>
                <li><a href="http://vos/display/CPEMPE/Multinet-R+Developer+Documentation">Confluence page</a> has been created with basic 'getting started' documentation</li>
                <li>To prevent software configuration issues, a virtual machine has been prepared and configured for MNR developments</li>
                <li>Charlotte and Jan prepared a clear list of MNR layers to be implemented; every developer</li>
                <ul>
                    <li>will need to refactor some existing MNR code</li>
                    <li>will need to implement a new MNR layer</li>
                    <li>will gain practical experience with the new TTOM name model</li>
                </ul>
            </ul>
        </slide>
    </story>

    <story epic="[MNR STABLEID]" title="Prototype feature DNA for stable UUIDs - Part 1: build and validate algorithm" status="done" sp="3">
        <slide>
            <h5>MNR Requirement: stable identifiers for all features over releases.</h5>
            <p>Note: this is temporary while TIF is master iso. MDS</p>
            <p>We came up with two possible approaches:</p>
            <div style="float:left;clear:none">
                <ul>
                    <li>
                        Create purely random GUIDs and keep track of assignment centrally <b>(DNA store)</b>
                        <ul>
                            <li style="color:green">uniqueness guaranteed</li>
                            <li style="color:red">huge performance and operational overhead</li>
                        </ul>
                    </li>
                    <li>
                        Create hashed GUIDs based on feature fields <b>(DNA hash)</b>
                        <ul>
                            <li style="color:green">almost no performance impact</li>
                            <li style="color:red">chance of hash collisions</li>
                        </ul>
                    </li>
                </ul>
            </div>
            <div style="float:right; clear:none">
                <img src="img/dnadatabase.jpg" width="200" height="150" />
            </div>
        </slide>
        <slide>
            <h5>DNA hash - an example</h5>
            <div style="float:left; clear:none">
                <ul>
                    <li>Create a DNA hash for a junction</li>
                    <li>Figure out "genes" for the junction DNA: <span style="color:blue">model</span>, <span style="color:red">type</span>, <span style="color:green">geometry</span>, <span style="color:orange">elevation</span></li>
                    <li>Use MD5 one-way hashing algorithm</li>
                </ul>
                <p> </p>
                <p align="center">md5 ( <span style="color:blue">"mnshp"</span> + <span style="color:red">"4120"</span> + <span style="color:green">"POINT(2 3)"</span> + <span style="color:orange">"1"</span> )</p>
                <p align="center">=</p>
                <p align="center">1075599d1cbfc5a1fdd0b3ad408fefab =&gt; MD5 hash</p>
                <p align="center">To UUID</p>
                <p align="center">550e8400-e29b-41d4-a716-446655440000 =&gt; Feature DNA</p>
                <h5>Challenge: Different features could have the same hash</h5>
            </div>
            <div style="float:right; clear:none">
                <img src="img/TooManyPigeons.jpg" width="200" height="150" />
            </div>
        </slide>
        <slide>
            <h5>DNA hash - prototype</h5>
            <ul>
                <li>Create DNA for a large amount of features</li>
                <li>Check if we have duplicate DNA: different feature, same DNA</li>
            </ul>
            <p><b>How we tried to prove this approach:</b></p>
            <ul>
                <li><p>Used several input products from different regions to create test input data (CSV)
                    <ul>
                        <li>MNSHP
                            <ul>
                                <li>coverage: NAM, EUR, LAM, SEA</li>
                                <li>releases: 1203, 1206, 1209, 1212, 1303, 1306</li>
                                <li>layers: WA / NW / AA / JC</li>
                            </ul>
                        </li>
                        <li>APT: All of EUR 13.03</li>
                        <li>Names: All of EUR 13.03</li>
                        <li>Total test data size: <span style="color:green">400GB</span></li>
                        <li>Total number of features: <span style="color:green">1,667,102,796</span></li>
                    </ul>
                </p></li>
                <li>
                    Create DNA for each input feature and find duplicates
                </li>
            </ul>
        </slide>
        <slide>
            <h5>DNA hash - results</h5>
            <img src="img/success.jpg" />
            <ul>
                <li>Good news: no collisions were found in the input data</li>
                <li>Result was mathematically expected (see <a href="http://vos.intra.local/display/~reid/2012/10/23/Stable+ID+generation+experiment+on+large+quantity+of+map+data">here</a>):</li>
                <li>TL;DR: chance for a collision is 1/28.147.497.671.066</li>
                <li>so that's one in twenty-eight trillion, 
one hundred forty-seven billion, 
four hundred ninety-seven million, 
six hundred seventy-one thousand, 
sixty-six</li>
            </ul>
        </slide>
        <slide>
            <h5>DNA hash - remarks and challenges</h5>
            <ul>
                <li>Genes need to be chosen per feature type (by specs?)</li>
                <li><p>Any field in the genes that changes will change its DNA</p>
                    <ul>
                        <li>Will result in DELETE/INSERT</li>
                        <li>Geometry may be a bad choice</li>
                        <li>Could use a hybrid approach: use stable TIF IDs when available (NW/JC), DNA hash otherwise (Restrictions)</li>
                    </ul>
                </li>
            </ul>
            <h5>DNA hash - next steps</h5>
            <ul>
                <li>Define genes per feature type</li>
                <li>Define how to store (?) DNA</li>
                <li>Implement on PDS</li>
            </ul>
        </slide>
    </story>
    
    <story epic="[MNR LAYER]" title="Locality index - Part 2: model localities in TTOM" status="not-done" sp="3">
        <slide>
            <div style="font-weight:bold">
            <p>EPIC: Serve Localities as TTOM features</p>
            </div>
            <ul>
                <em style="color: grey">
                <li>Step 1: Create locality index product during current TIF2TTOM converter</li>
                </em>
                <li>Step 2: Load locality index product back into PDS and serve them as TTOM features</li>
            </ul>
            <p>Step 2:</p>
            <ul>
                <li>DONE:</li>
                <ul>
                   <li>Store TTOM Locality features with geometry</li>
                   <li>Localities are seamed on dataset borders</li>
                   <li>Add names according to TTOM name model</li>
                </ul>
                <li>TODO:</li>
                <ul>
                   <li>Fix potential missing Name Component Key on NAM datasets</li>
                   <li>Solve TIF2MN bugs</li>
                </ul>
            </ul>
        </slide>
        <slide>
            <p>Process overview</p>
            <img src="img/locality_index_ttom_process.png"/>
        </slide>
    </story>    

    <initscript>
    </initscript>

</slides>
